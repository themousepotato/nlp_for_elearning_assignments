{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Algorithm</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A bigram language model is trained from the corpus. <br />\n",
    "* Another bigram language model is trained after reversing the sentences from the corpus. <br />\n",
    "* Given the context word, the model randomly decides to add a prefix or a suffix.<br />\n",
    "* To add prefix, we generate the word from the language model trained of reversed sentences.<br />\n",
    "* To add suffix, we generate the word from the language model trained on original sentences.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm applied on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './corpus.txt'\n",
    "\n",
    "stopwords = ['', '(', ')', '{', '}', '\\\\', '--', ':', '-', \"'s\"]\n",
    "punc = string.punctuation + \"``\" + \"''\" + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH, 'r') as f:\n",
    "    data = f.read().lower().replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3954021"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(words)\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_rev_words(data):\n",
    "    sents = []\n",
    "    for sent in nltk.sent_tokenize(data):\n",
    "        words = [word for word in nltk.word_tokenize(sent) if word not in stopwords and word not in punc]\n",
    "        sents.append(list(reversed(words)))\n",
    "        \n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = tokenized_words(data)\n",
    "rev_sents = tokenized_rev_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [word for sent in sents for word in sent]\n",
    "rev_train_corpus = [word for sent in rev_sents for word in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666665"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_freq_dist(corpus, ngram=1):\n",
    "    if isinstance(corpus, list) and len(corpus)>0:\n",
    "        train_corpus=corpus\n",
    "    elif type(corpus) is str:\n",
    "        train_corpus=nltk.word_tokenize(corpus)\n",
    "    else:\n",
    "        print('Error')\n",
    "        return None\n",
    "    \n",
    "    freq_dist=None\n",
    "    if ngram==1:\n",
    "        freq_dist = nltk.FreqDist(train_corpus) #freq distibution for unigrams\n",
    "    elif ngram==2:\n",
    "        freq_dist = nltk.ConditionalFreqDist(nltk.ngrams(train_corpus, 2))# conditional freq dist for bigrams\n",
    "    elif ngram==3:\n",
    "        trigrams_as_bigrams=[]\n",
    "        trigram =[a for a in ngrams(train_corpus, 3)]\n",
    "        trigrams_as_bigrams.extend([((t[0],t[1]), t[2]) for t in trigram])\n",
    "        freq_dist = nltk.ConditionalFreqDist(trigrams_as_bigrams)# conditional freq dist for trigrams\n",
    "    else:\n",
    "        print('Supported upto trigrams only')\n",
    "    return freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd_2gram = ngram_freq_dist(train_corpus, 2)\n",
    "cfd_2gram_rev = ngram_freq_dist(rev_train_corpus, 2)\n",
    "\n",
    "cpd_2gram = nltk.ConditionalProbDist(cfd_2gram, nltk.MLEProbDist)\n",
    "cpd_2gram_rev = nltk.ConditionalProbDist(cfd_2gram_rev, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_bigram_model_random(cprob_2gram, cprob_2gram_rev, initialword, numwords=15):\n",
    "    text = initialword\n",
    "    suf_word = initialword\n",
    "    pre_word = initialword\n",
    "    for index in range(numwords):\n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                suf_word = cprob_2gram[suf_word].generate()\n",
    "                text = text + \" \" + suf_word\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "        else:\n",
    "            try: \n",
    "                pre_word = cprob_2gram_rev[pre_word].generate()\n",
    "                text = pre_word + ' ' + text\n",
    "            except Exception as e:\n",
    "                print('Can not generate the sentence')\n",
    "                return\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Results</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his grave problem is he believes donald trump foundation of rt berniesanders holds a great to\n",
      "----------------------------------------\n",
      "our justice reform a trump believes that donald trump pay to cut social security issues these\n",
      "----------------------------------------\n",
      "13th because americans if donald trump got to see her greeting western industrialized nation in the\n",
      "----------------------------------------\n",
      "a government makes billions in july calling for president trump from every person than 56 of\n",
      "----------------------------------------\n",
      "the drug prices you still beat trump is not class knows how would be too many\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_txt_bigram_model_random(cpd_2gram, cpd_2gram_rev, 'trump'))\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our algorithm applied on a small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_corpus = 'the day is quite bright today i am feeling very good \\\n",
    "this is my best feeling i have ever experienced the dog is sleeping peacefully at one corner \\\n",
    "the coffee is warm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'day',\n",
       " 'is',\n",
       " 'quite',\n",
       " 'bright',\n",
       " 'today',\n",
       " 'i',\n",
       " 'am',\n",
       " 'feeling',\n",
       " 'very',\n",
       " 'good',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'best',\n",
       " 'feeling',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'experienced',\n",
       " 'the',\n",
       " 'dog',\n",
       " 'is',\n",
       " 'sleeping',\n",
       " 'peacefully',\n",
       " 'at',\n",
       " 'one',\n",
       " 'corner',\n",
       " 'the',\n",
       " 'coffee',\n",
       " 'is',\n",
       " 'warm']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = tokenized_words(small_corpus)[0]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': FreqDist({'day': 1, 'dog': 1, 'coffee': 1}),\n",
       " 'day': FreqDist({'is': 1}),\n",
       " 'is': FreqDist({'quite': 1, 'my': 1, 'sleeping': 1, 'warm': 1}),\n",
       " 'quite': FreqDist({'bright': 1}),\n",
       " 'bright': FreqDist({'today': 1}),\n",
       " 'today': FreqDist({'i': 1}),\n",
       " 'i': FreqDist({'am': 1, 'have': 1}),\n",
       " 'am': FreqDist({'feeling': 1}),\n",
       " 'feeling': FreqDist({'very': 1, 'i': 1}),\n",
       " 'very': FreqDist({'good': 1}),\n",
       " 'good': FreqDist({'this': 1}),\n",
       " 'this': FreqDist({'is': 1}),\n",
       " 'my': FreqDist({'best': 1}),\n",
       " 'best': FreqDist({'feeling': 1}),\n",
       " 'have': FreqDist({'ever': 1}),\n",
       " 'ever': FreqDist({'experienced': 1}),\n",
       " 'experienced': FreqDist({'the': 1}),\n",
       " 'dog': FreqDist({'is': 1}),\n",
       " 'sleeping': FreqDist({'peacefully': 1}),\n",
       " 'peacefully': FreqDist({'at': 1}),\n",
       " 'at': FreqDist({'one': 1}),\n",
       " 'one': FreqDist({'corner': 1}),\n",
       " 'corner': FreqDist({'the': 1}),\n",
       " 'coffee': FreqDist({'is': 1})}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_freq_dist = ngram_freq_dist(corpus, 2)\n",
    "dict(bigrams_freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm',\n",
       " 'is',\n",
       " 'coffee',\n",
       " 'the',\n",
       " 'corner',\n",
       " 'one',\n",
       " 'at',\n",
       " 'peacefully',\n",
       " 'sleeping',\n",
       " 'is',\n",
       " 'dog',\n",
       " 'the',\n",
       " 'experienced',\n",
       " 'ever',\n",
       " 'have',\n",
       " 'i',\n",
       " 'feeling',\n",
       " 'best',\n",
       " 'my',\n",
       " 'is',\n",
       " 'this',\n",
       " 'good',\n",
       " 'very',\n",
       " 'feeling',\n",
       " 'am',\n",
       " 'i',\n",
       " 'today',\n",
       " 'bright',\n",
       " 'quite',\n",
       " 'is',\n",
       " 'day',\n",
       " 'the']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reversing the corpus\n",
    "rev_corpus = tokenized_rev_words(small_corpus)[0]\n",
    "rev_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm': FreqDist({'is': 1}),\n",
       " 'is': FreqDist({'coffee': 1, 'dog': 1, 'this': 1, 'day': 1}),\n",
       " 'coffee': FreqDist({'the': 1}),\n",
       " 'the': FreqDist({'corner': 1, 'experienced': 1}),\n",
       " 'corner': FreqDist({'one': 1}),\n",
       " 'one': FreqDist({'at': 1}),\n",
       " 'at': FreqDist({'peacefully': 1}),\n",
       " 'peacefully': FreqDist({'sleeping': 1}),\n",
       " 'sleeping': FreqDist({'is': 1}),\n",
       " 'dog': FreqDist({'the': 1}),\n",
       " 'experienced': FreqDist({'ever': 1}),\n",
       " 'ever': FreqDist({'have': 1}),\n",
       " 'have': FreqDist({'i': 1}),\n",
       " 'i': FreqDist({'feeling': 1, 'today': 1}),\n",
       " 'feeling': FreqDist({'best': 1, 'am': 1}),\n",
       " 'best': FreqDist({'my': 1}),\n",
       " 'my': FreqDist({'is': 1}),\n",
       " 'this': FreqDist({'good': 1}),\n",
       " 'good': FreqDist({'very': 1}),\n",
       " 'very': FreqDist({'feeling': 1}),\n",
       " 'am': FreqDist({'i': 1}),\n",
       " 'today': FreqDist({'bright': 1}),\n",
       " 'bright': FreqDist({'quite': 1}),\n",
       " 'quite': FreqDist({'is': 1}),\n",
       " 'day': FreqDist({'the': 1})}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_freq_dist_rev = ngram_freq_dist(rev_corpus, 2)\n",
    "dict(bigrams_freq_dist_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, after reversing the corpus, we get the appropriate frequency distribution format which is required for generating prefixes. Prefix can be generated from freq. distribtion by converting it into a probability distribution and then generating words from it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
